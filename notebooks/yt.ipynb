{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d52ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 11:23:08,485 - root - INFO - Logging configured successfully\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "\n",
    "logging.info(\"Logging configured successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9afeba91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2b89328",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/master_g/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m YoutubeLoader\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_community/document_loaders/__init__.py:740\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) -> Any:\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m _module_lookup:\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m         module = \u001b[43mimportlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_module_lookup\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    741\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[32m    742\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_community/document_loaders/youtube.py:16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m model_validator\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataclasses\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dataclass\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseLoader\n\u001b[32m     18\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     20\u001b[39m SCOPES = [\u001b[33m\"\u001b[39m\u001b[33mhttps://www.googleapis.com/auth/youtube.readonly\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_community/document_loaders/base.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseBlobParser, BaseLoader\n\u001b[32m      3\u001b[39m __all__ = [\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBaseBlobParser\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mBaseLoader\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen importlib._bootstrap>:1412\u001b[39m, in \u001b[36m_handle_fromlist\u001b[39m\u001b[34m(module, fromlist, import_, recursive)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_core/document_loaders/__init__.py:33\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(attr_name)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(attr_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m     32\u001b[39m     module_name = _dynamic_imports.get(attr_name)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     result = \u001b[43mimport_attr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattr_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m__spec__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     \u001b[38;5;28mglobals\u001b[39m()[attr_name] = result\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_core/_import_utils.py:35\u001b[39m, in \u001b[36mimport_attr\u001b[39m\u001b[34m(attr_name, module_name, package)\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m         module = \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodule_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m     37\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_core/document_loaders/base.py:19\u001b[39m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocuments\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Blob\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m     21\u001b[39m     _HAS_TEXT_SPLITTERS = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_text_splitters/__init__.py:38\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnltk\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NLTKTextSplitter\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PythonCodeTextSplitter\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     39\u001b[39m     SentenceTransformersTokenTextSplitter,\n\u001b[32m     40\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspacy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpacyTextSplitter\n\u001b[32m     43\u001b[39m __all__ = [\n\u001b[32m     44\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mCharacterTextSplitter\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     45\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mElementType\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msplit_text_on_tokens\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     68\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/langchain_text_splitters/sentence_transformers.py:11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextSplitter, Tokenizer, split_text_on_tokens\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;66;03m# Type ignores needed as long as sentence-transformers doesn't support Python 3.14.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# type: ignore[import-not-found, unused-ignore]\u001b[39;00m\n\u001b[32m     12\u001b[39m         SentenceTransformer,\n\u001b[32m     13\u001b[39m     )\n\u001b[32m     15\u001b[39m     _HAS_SENTENCE_TRANSFORMERS = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/backend/__init__.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     _save_pretrained_wrapper,\n\u001b[32m      8\u001b[39m     backend_should_export,\n\u001b[32m      9\u001b[39m     backend_warn_to_save,\n\u001b[32m     10\u001b[39m     save_or_push_to_hub_model,\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m __all__ = [\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mload_onnx_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mload_openvino_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msave_or_push_to_hub_model\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     23\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/backend/quantize.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Literal\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m save_or_push_to_hub_model\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutil\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m disable_datasets_caching, is_datasets_available\n\u001b[32m      9\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/util/__init__.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhard_negatives\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mine_hard_negatives\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m append_to_last_row, disable_datasets_caching, disable_logging, fullname, import_from_string\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mretrieval\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     community_detection,\n\u001b[32m     17\u001b[39m     information_retrieval,\n\u001b[32m     18\u001b[39m     paraphrase_mining,\n\u001b[32m     19\u001b[39m     paraphrase_mining_embeddings,\n\u001b[32m     20\u001b[39m     semantic_search,\n\u001b[32m     21\u001b[39m )\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimilarity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     23\u001b[39m     cos_sim,\n\u001b[32m     24\u001b[39m     dot_score,\n\u001b[32m   (...)\u001b[39m\u001b[32m     32\u001b[39m     pytorch_cos_sim,\n\u001b[32m     33\u001b[39m )\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     _convert_to_batch,\n\u001b[32m     36\u001b[39m     _convert_to_batch_tensor,\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     truncate_embeddings,\n\u001b[32m     44\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/util/retrieval.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtqdm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01msimilarity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cos_sim\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtensor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_embeddings\n\u001b[32m     17\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sentence_transformers/util/similarity.py:5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pairwise_distances\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/__init__.py:70\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[32m     63\u001b[39m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[32m     64\u001b[39m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __check_build, _distributor_init  \u001b[38;5;66;03m# noqa: E402 F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[32m     73\u001b[39m _submodules = [\n\u001b[32m     74\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcalibration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     75\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcluster\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    111\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompose\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    112\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/base.py:19\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_missing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_pandas_na, is_scalar_nan\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/__init__.py:9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_indexing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, resample, shuffle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/_chunking.py:11\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[32m     15\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/validation.py:24\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     DataConversionWarning,\n\u001b[32m     21\u001b[39m     NotFittedError,\n\u001b[32m     22\u001b[39m     PositiveSpectrumWarning,\n\u001b[32m     23\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     _asarray_with_order,\n\u001b[32m     26\u001b[39m     _convert_to_numpy,\n\u001b[32m     27\u001b[39m     _is_numpy_namespace,\n\u001b[32m     28\u001b[39m     _max_precision_float_dtype,\n\u001b[32m     29\u001b[39m     get_namespace,\n\u001b[32m     30\u001b[39m     get_namespace_and_device,\n\u001b[32m     31\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_pandas_df, is_pandas_df_or_series\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_isfinite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/_array_api.py:20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexternals\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_df_or_series\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[32m     23\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mxpx\u001b[39m\u001b[33m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/sklearn/utils/fixes.py:16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msparse\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinalg\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstats\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/scipy/stats/__init__.py:628\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m \n\u001b[32m    624\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m    626\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_warnings_errors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[32m    627\u001b[39m                                DegenerateDataWarning, FitError)\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats_py\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_variation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/scipy/stats/_stats_py.py:49\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# Import unused here but needs to stay until end of deprecation periode\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# See https://github.com/scipy/scipy/issues/15765#issuecomment-1875564522\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m linalg  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m distributions\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _mstats_basic \u001b[38;5;28;01mas\u001b[39;00m mstats_basic\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_stats_mstats_common\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m theilslopes, siegelslopes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/scipy/stats/distributions.py:14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _discrete_distns\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_continuous_distns\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_levy_stable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m levy_stable\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_discrete_distns\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_entropy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m entropy\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/MultiAgentSystem/venv/lib/python3.12/site-packages/scipy/stats/_levy_stable/__init__.py:1159\u001b[39m\n\u001b[32m   1155\u001b[39m \u001b[38;5;66;03m# cotes numbers - see sequence from http://oeis.org/A100642\u001b[39;00m\n\u001b[32m   1156\u001b[39m Cotes_table = np.array(\n\u001b[32m   1157\u001b[39m     [[], [\u001b[32m1\u001b[39m]] + [v[\u001b[32m2\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m _builtincoeffs.values()], dtype=\u001b[38;5;28mobject\u001b[39m\n\u001b[32m   1158\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m Cotes = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCotes_table\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconstant\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mCotes_table\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpdf_from_cf_with_fft\u001b[39m(cf, h=\u001b[32m0.01\u001b[39m, q=\u001b[32m9\u001b[39m, level=\u001b[32m3\u001b[39m):\n\u001b[32m   1168\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculates pdf from characteristic function.\u001b[39;00m\n\u001b[32m   1169\u001b[39m \n\u001b[32m   1170\u001b[39m \u001b[33;03m    Uses fast Fourier transform with Newton-Cotes integration following [WZ].\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1203\u001b[39m \u001b[33;03m        to compute densities of stable distribution.\u001b[39;00m\n\u001b[32m   1204\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40ff019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810536f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 11:23:13,852 - src.graph.workflow - INFO - Initializing Workflow graph\n",
      "2026-02-05 11:23:13,860 - src.graph.workflow - INFO - Starting workflow run for url: https://www.youtube.com/watch?v=jt1XlpItb-8\n",
      "2026-02-05 11:23:13,861 - src.nodes.ingest - INFO - Starting ingestion for video: https://www.youtube.com/watch?v=jt1XlpItb-8\n",
      "2026-02-05 11:23:15,132 - src.nodes.ingest - INFO - Retrieved transcript length: 14664 chars\n",
      "2026-02-05 11:23:15,133 - src.nodes.ingest - INFO - Created 8 chunks\n",
      "2026-02-05 11:23:15,295 - src.nodes.gatekeeper - INFO - Gatekeeper: Found relevant medical content. (0.40)\n",
      "2026-02-05 11:23:15,296 - src.nodes.extractor - INFO - Extractor processing chunk of length 1987\n",
      "2026-02-05 11:23:15,298 - src.nodes.extractor - INFO - Extractor processing chunk of length 1975\n",
      "2026-02-05 11:23:15,300 - src.nodes.extractor - INFO - Extractor processing chunk of length 1835\n",
      "2026-02-05 11:23:15,300 - src.nodes.extractor - INFO - Extractor processing chunk of length 1976\n",
      "2026-02-05 11:23:15,302 - src.nodes.extractor - INFO - Extractor processing chunk of length 1995\n",
      "2026-02-05 11:23:15,302 - src.nodes.extractor - INFO - Extractor processing chunk of length 1923\n",
      "2026-02-05 11:23:15,304 - src.nodes.extractor - INFO - Extractor processing chunk of length 1702\n",
      "2026-02-05 11:23:15,306 - src.nodes.extractor - INFO - Extractor processing chunk of length 1892\n",
      "2026-02-05 11:23:24,510 - src.nodes.extractor - INFO - Extractor found 2 claims\n",
      "2026-02-05 11:23:24,511 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='Homeopathic products do not require evidence of therapeutic efficacy for approval.', quote_verbatim='... nie wymaga przedstawiania przez producenta dowodów skuteczności terapeutycznej...'), Claim(topic='Homeopathy', statement='Homeopathic products that do not contain indications for use do not require documentation of their effectiveness.', quote_verbatim='... ale tylko te, które między innymi nie zawierają wskazań do stosowania.')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:31,243 - src.nodes.extractor - INFO - Extractor found 3 claims\n",
      "2026-02-05 11:23:31,244 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='According to the law of minimal dose, smaller doses of a substance are more effective.', quote_verbatim='...im mniejsza dawka leku, tym większa jego skuteczność...'), Claim(topic='Homeopathy', statement='The efficacy of homeopathic remedies is due to their ability to cause trauale changes in the solution.', quote_verbatim='...może to dobrze, bo mogłoby to oznaczać że woda z kranu pamiętałaby o tym, że jeszcze niedawno była wodą w toalecie sąsiada...'), Claim(topic='Homeopathy', statement='The potency of homeopathic remedies is determined by the degree of dilution.', quote_verbatim='...litery nawiązują do konkretnej skali rozcieńczenia, a cyfry do krotności tego rozcieńczenia...')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:39,440 - src.nodes.extractor - INFO - Extractor found 7 claims\n",
      "2026-02-05 11:23:39,441 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='According to science, homeopathy has no right to exist and should not be in medicine.', quote_verbatim='Nauka uważa, że homeopatia nie ma prawa działać i nie ma dla niej miejsca w medycynie.'), Claim(topic='Homeopathic products', statement='Many homeopathic products have specific indications and should have accompanying documentation.', quote_verbatim='Wiele produktów homeopatycznych ma określone wskazania więc musiało też przedstawić taką dokumentację.'), Claim(topic='Homeopathic products', statement='Due to the lack of documentation, it is difficult to find studies confirming their effectiveness.', quote_verbatim='Gdzie ona w takim razie jest? Jak zauważył dziennikarz Łukasz Łamża, obowiązek publikacji takich dokumentów dotyczy produktów leczniczych dopuszczonych do obrotu od dnia 25 listopada 2013 roku...'), Claim(topic='Homeopathic products', statement='Some homeopathic products may provide relief due to their auxiliary substances.', quote_verbatim='Inna, ale też ciekawą sprawą jest to, że często pewną ulgę mogą przynieść same substancje pomocnicze.'), Claim(topic='Homeopathic products', statement='Glycerin and vaseline in homeopathic creams for hemorrhoids can provide relief by coating and moisturizing the irritated mucous membrane.', quote_verbatim='Na przykład substancje pomocnicze homeopatycznej maści na hemoroidy to między innymi gliceryna i wazelina, które mogą powlekać i nawilżyć podrażnioną śluzówkę...'), Claim(topic='Homeopathic products', statement='Syrups for dry cough often contain sugar as an auxiliary substance, which can provide relief by coating the throat.', quote_verbatim='Szczególnie jeśli związany jest on również właśnie z suchością i podrażnieniem gardła. Syropy na suchy kaszel, które jako substancje pomocniczą zawierają sacharozę...'), Claim(topic='Homeopathy', statement='The dilutions in homeopathic products are often so low that it is difficult to find active molecules.', quote_verbatim='Wiemy, że rozcieńczenia składników w niektórych preparatach są na tyle niskie, że trudno może być znaleźć w nich cząsteczki substancji aktywnej.')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:41,284 - src.nodes.extractor - INFO - Extractor found 3 claims\n",
      "2026-02-05 11:23:41,285 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='According to current laws of chemistry, physics, and pharmacology, it is difficult to prove that homeopathy works.', quote_verbatim='Według obecnie znanych praw chemii, fizyki i farmakologii, ciężko wykazać, by homeopatia miała prawo działać.'), Claim(topic='Homeopathy', statement='There is no reliable evidence that homeopathy is effective.', quote_verbatim='Kompleksowa ocena dowodów z 2015 roku przeprowadzona przez australijską radę do spraw zdrowia i badań medycznych, wykazała, że nie ma wiarygodnych dowodów na to, że homeopatia jest skuteczna.'), Claim(topic='Homeopathy', statement='In many cases, it is impossible to determine the mechanism of action of a given drug because the final product does not contain a measurable amount of active substance.', quote_verbatim='Poza tym w wielu przypadkach niemożliwe jest ustalenie mechanizmu działania danego leku, bo finalny produkt nie zawiera oznaczalnej ilości substancji czynnej.')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:46,936 - src.nodes.extractor - INFO - Extractor found 3 claims\n",
      "2026-02-05 11:23:46,937 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='Homeopathic remedies may cause side effects such as allergic reactions or poisoning.', quote_verbatim='...są dowody na to by homeopatia mogła potencjalnie szkodzić pacjentom, zarówno w ten sposób bezpośredni, czyli powodując na przykład uczulenia czy zatrucia...'), Claim(topic='Homeopathy', statement='Homeopathic remedies may delay proper medical treatment.', quote_verbatim='...opóźniając na przykład prawidłowe według medycyny opartej na dowodach leczenie.'), Claim(topic='Placebo Effect', statement='The placebo effect can be a significant factor in the efficacy of homeopathic remedies.', quote_verbatim='...porównując homeopatię do placebo nie możemy powiedzieć, że nie jest skuteczna.')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:50,695 - src.nodes.extractor - INFO - Extractor found 3 claims\n",
      "2026-02-05 11:23:50,696 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='According to homeopathic principles, extremely diluted substances do not contain any active molecules.', quote_verbatim='...tak duże rozcieńczenie, że w zasadzie można uznać że nie znajdziemy tam ani jednego atomu substancji zawartych w ekstrakcie...'), Claim(topic='Homeopathy', statement='The process of dilution in homeopathy involves repeatedly adding a solvent to the solution, resulting in an extremely diluted substance.', quote_verbatim='...Upłynniamy serce i wątrobę kaczki. Jedną część takiego roztworu łączymy z 90 częściami rozpuszczalnika, wytrząsamy i mamy rozcieńczenie 1k...'), Claim(topic='Homeopathy', statement='The dilution process in homeopathy can be repeated multiple times, resulting in a substance with an extremely low concentration of active molecules.', quote_verbatim='...W przypadku przygotowywania roztworu 200k, taką czynność powtórzono 200 razy, co miałoby dać jego stężenie o wartości 100 do potęgi minus 400...')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:23:55,735 - src.nodes.extractor - INFO - Extractor found 3 claims\n",
      "2026-02-05 11:23:55,735 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='According to homeopathic procedure, products are made from homeopathic primary substances or their mixtures.', quote_verbatim='...'), Claim(topic='Homeopathy', statement='Homeopathy is based on the theory that similar causes similar effects.', quote_verbatim='podobne leczy podobne'), Claim(topic='Homeopathy', statement='The homeopathic procedure involves using substances with a much lower concentration than the original substance.', quote_verbatim='z o wiele mniejszym stężeniem')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:24:00,936 - src.nodes.extractor - INFO - Extractor found 6 claims\n",
      "2026-02-05 11:24:00,936 - src.nodes.extractor - INFO - \n",
      "\n",
      "CLAIM [Claim(topic='Homeopathy', statement='The water remembers its past contact with the extract from the heart and liver of a duck.', quote_verbatim='Woda oczywiście musi zostać odparowana, żeby produkt miał postać suchych granulek, więc podejrzewam, że przekazała po prostu swoją pamięć właśnie tym granulkom.'), Claim(topic='Homeopathy', statement='The extract from the heart and liver of a duck is used to treat flu-like symptoms.', quote_verbatim='Tak i w związku z tym dziś osobom z przeziębieniem nadal może być podawany preparat właśnie z serca i wątroby kaczki.'), Claim(topic='Homeopathy', statement='The law of infinitesimals states that smaller doses are more potent.', quote_verbatim='Tak czy siak właśnie stąd podejrzenie, że podroby z kaczki miałyby leczyć objawy właśnie grypopodobne.'), Claim(topic='Homeopathy', statement='Rumianek is present in a concentration of 1 part per trillion.', quote_verbatim='rumianek 9 CH, czyli 10 do potęgi minus 18'), Claim(topic='Homeopathy', statement='The dilution of 5CH means that the substance has been diluted one to hundred five times.', quote_verbatim='czyli rozcieńczenie jeden do stu przeprowadzone pięciokrotnie, co daje stężenie 10 do potęgi minus 10'), Claim(topic='Homeopathy', statement='Homeopathic products often use plant-based ingredients.', quote_verbatim='Składniki roślinne jak najbardziej zawierają różne substancje aktywne, jednak ziołolecznictwo nie bazuje na takim rozcieńczaniu ekstraktów')] claims\n",
      "\n",
      "\n",
      "2026-02-05 11:24:00,937 - src.nodes.refiner - INFO - Deduplicator received 30 raw claims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-02-05 11:24:10,339 - src.nodes.refiner - INFO - Batch 1/2 processed. Found 5 unique items.\n",
      "2026-02-05 11:24:20,269 - src.nodes.refiner - INFO - Batch 2/2 processed. Found 5 unique items.\n",
      "2026-02-05 11:24:20,270 - src.nodes.refiner - INFO - Refiner finished. Reduced to 10 unique claims\n",
      "2026-02-05 11:24:20,270 - src.nodes.refiner - INFO - \n",
      "\n",
      "[UniqueClaim(topic='Homeopathy', statement='Homeopathy is based on the theory that similar causes similar effects.', quote_verbatim='According to homeopathic procedure, products are made from homeopathic primary substances or their mixtures.', verification_tool='TAVILY'), UniqueClaim(topic='Dilution', statement='The potency of homeopathic remedies is determined by the degree of dilution.', quote_verbatim='The process of dilution in homeopathy involves repeatedly adding a solvent to the solution, resulting in an extremely diluted substance.', verification_tool='TAVILY'), UniqueClaim(topic='Efficacy', statement='There is no reliable evidence that homeopathy is effective.', quote_verbatim='The efficacy of homeopathic remedies is due to their ability to cause trauale changes in the solution.', verification_tool='PUBMED'), UniqueClaim(topic='Ingredients', statement='Homeopathic products often use plant-based ingredients.', quote_verbatim='Glycerin and vaseline in homeopathic creams for hemorrhoids can provide relief by coating and moisturizing the irritated mucous membrane.', verification_tool='TAVILY'), UniqueClaim(topic='Regulation', statement='Homeopathic products do not require evidence of therapeutic efficacy for approval.', quote_verbatim='Many homeopathic products have specific indications and should have accompanying documentation.', verification_tool='PUBMED'), UniqueClaim(topic='Law of Minimal Dose', statement='Smaller doses of a substance are more effective.', quote_verbatim='According to the law of minimal dose, smaller doses of a substance are more effective.', verification_tool='PUBMED'), UniqueClaim(topic='Dilution Factor', statement='The dilution of 5CH means that the substance has been diluted one to hundred five times.', quote_verbatim='3 Claim: The dilution of 5CH means that the substance has been diluted one to hundred five times.', verification_tool='PUBMED'), UniqueClaim(topic='Rumianek Concentration', statement='Rumianek is present in a concentration of 1 part per trillion.', quote_verbatim='2 Claim: Rumianek is present in a concentration of 1 part per trillion.', verification_tool='PUBMED'), UniqueClaim(topic='Duck Extract', statement='The extract from the heart and liver of a duck is used to treat flu-like symptoms.', quote_verbatim='5 Claim: The extract from the heart and liver of a duck is used to treat flu-like symptoms.', verification_tool='PUBMED'), UniqueClaim(topic='Dry Cough Syrups', statement='Syrups for dry cough often contain sugar as an auxiliary substance, which can provide relief by coating the throat.', quote_verbatim='6 Claim: Syrups for dry cough often contain sugar as an auxiliary substance, which can provide relief by coating the throat.', verification_tool='TAVILY')]\n",
      "\n",
      "\n",
      "2026-02-05 11:24:20,272 - src.nodes.research - INFO - Researching claim: Homeopathy is based on the theory that similar cau...\n",
      "2026-02-05 11:24:20,272 - src.nodes.research - INFO - Researching claim: The potency of homeopathic remedies is determined ...\n",
      "2026-02-05 11:24:20,273 - src.nodes.research - INFO - Researching claim: There is no reliable evidence that homeopathy is e...\n",
      "2026-02-05 11:24:20,273 - src.nodes.research - INFO - Researching claim: Homeopathic products often use plant-based ingredi...\n",
      "2026-02-05 11:24:20,274 - src.nodes.research - INFO - Researching claim: Homeopathic products do not require evidence of th...\n",
      "2026-02-05 11:24:20,276 - src.nodes.research - INFO - Researching claim: Smaller doses of a substance are more effective....\n",
      "2026-02-05 11:24:20,276 - src.nodes.research - INFO - Researching claim: The dilution of 5CH means that the substance has b...\n",
      "2026-02-05 11:24:20,277 - src.nodes.research - INFO - Researching claim: Rumianek is present in a concentration of 1 part p...\n",
      "2026-02-05 11:24:20,279 - src.nodes.research - INFO - Researching claim: The extract from the heart and liver of a duck is ...\n",
      "2026-02-05 11:24:20,279 - src.nodes.research - INFO - Researching claim: Syrups for dry cough often contain sugar as an aux...\n",
      "2026-02-05 11:24:22,702 - src.nodes.research - INFO - Found 5 papers via Tavily\n",
      "2026-02-05 11:24:22,703 - src.nodes.judge - INFO - Judging claim: The potency of homeopathic remedies is determined ... with 5 papers\n",
      "2026-02-05 11:24:23,040 - src.nodes.research - INFO - Found 5 papers via PubMed\n",
      "2026-02-05 11:24:23,041 - src.nodes.judge - INFO - Judging claim: Homeopathic products do not require evidence of th... with 5 papers\n",
      "2026-02-05 11:24:23,401 - src.nodes.research - INFO - Found 5 papers via Tavily\n",
      "2026-02-05 11:24:23,402 - src.nodes.judge - INFO - Judging claim: Homeopathy is based on the theory that similar cau... with 5 papers\n",
      "2026-02-05 11:24:23,902 - src.nodes.research - INFO - Found 4 papers via PubMed\n",
      "2026-02-05 11:24:23,903 - src.nodes.judge - INFO - Judging claim: Smaller doses of a substance are more effective.... with 4 papers\n",
      "2026-02-05 11:24:24,454 - src.nodes.research - INFO - Found 5 papers via Tavily\n",
      "2026-02-05 11:24:24,456 - src.nodes.judge - INFO - Judging claim: Homeopathic products often use plant-based ingredi... with 5 papers\n",
      "2026-02-05 11:24:24,568 - src.nodes.research - INFO - Found 5 papers via PubMed\n",
      "2026-02-05 11:24:24,569 - src.nodes.judge - INFO - Judging claim: There is no reliable evidence that homeopathy is e... with 5 papers\n",
      "2026-02-05 11:24:24,575 - src.nodes.research - WARNING - PubMed found 0 papers. Fallback to Tavily General for: 'Rumianek concentration 1 part per trillion'\n",
      "2026-02-05 11:24:24,718 - src.nodes.research - INFO - Found 4 papers via PubMed\n",
      "2026-02-05 11:24:24,719 - src.nodes.judge - INFO - Judging claim: The dilution of 5CH means that the substance has b... with 4 papers\n",
      "2026-02-05 11:24:25,409 - src.nodes.research - INFO - Found 5 papers via Tavily\n",
      "2026-02-05 11:24:25,410 - src.nodes.judge - INFO - Judging claim: Syrups for dry cough often contain sugar as an aux... with 5 papers\n",
      "2026-02-05 11:24:25,700 - src.nodes.research - INFO - Found 5 papers via Tavily Fallback\n",
      "2026-02-05 11:24:25,701 - src.nodes.judge - INFO - Judging claim: Rumianek is present in a concentration of 1 part p... with 5 papers\n",
      "2026-02-05 11:24:26,299 - src.nodes.research - WARNING - PubMed found 0 papers. Fallback to Tavily General for: 'Duck extract flu symptoms treatment efficacy study'\n",
      "2026-02-05 11:24:27,429 - src.nodes.judge - INFO - Verdict for claim: False\n",
      "2026-02-05 11:24:28,035 - src.nodes.research - INFO - Found 5 papers via Tavily Fallback\n",
      "2026-02-05 11:24:28,035 - src.nodes.judge - INFO - Judging claim: The extract from the heart and liver of a duck is ... with 5 papers\n",
      "2026-02-05 11:24:29,306 - src.nodes.judge - INFO - Verdict for claim: False\n",
      "2026-02-05 11:24:32,174 - src.nodes.judge - INFO - Verdict for claim: False\n",
      "2026-02-05 11:24:33,838 - src.nodes.judge - INFO - Verdict for claim: True\n",
      "2026-02-05 11:24:39,293 - src.nodes.judge - INFO - Verdict for claim: True\n",
      "2026-02-05 11:24:43,159 - src.nodes.judge - INFO - Verdict for claim: False\n",
      "2026-02-05 11:24:44,741 - src.nodes.judge - INFO - Verdict for claim: True\n",
      "2026-02-05 11:24:47,525 - src.nodes.judge - INFO - Verdict for claim: Unverified\n",
      "2026-02-05 11:24:49,200 - src.nodes.judge - INFO - Verdict for claim: True\n",
      "2026-02-05 11:24:52,055 - src.nodes.judge - INFO - Verdict for claim: False\n",
      "2026-02-05 11:24:52,056 - src.nodes.reporter - INFO - Generating final report based on 10 verdicts\n",
      "# Fact-Check Report\n",
      "\n",
      "Analyzed claims: **10**. Debunked: **5**.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. ❌ Verdict: False\n",
      "**Claim:** Homeopathy is based on the theory that similar causes similar effects.\n",
      "**Explanation:** The provided evidence confirms that homeopathy does not have reliable scientific grounding. The core principle of 'like cures like' is based on a flawed understanding of pharmacodynamics and has been extensively debunked by multiple systematic reviews and meta-analyses. The claim that homeopathy is based on the theory that similar causes similar effects is contradicted by high-quality evidence, including a 2016 systematic review and meta-analysis that found no compelling evidence of effect other than placebo.\n",
      "**Sources:**\n",
      "- (https://www.healthline.com/health/what-is-homeopathy)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC9343926/)\n",
      "- (https://www.sciencedirect.com/science/article/pii/S0965229913001544)\n",
      "- (https://www.hri-research.org/resources/homeopathy-faqs/like-cures-like/)\n",
      "- (https://en.wikipedia.org/wiki/Evidence_and_efficacy_of_homeopathy)\n",
      "\n",
      "---\n",
      "### 2. ❌ Verdict: False\n",
      "**Claim:** The potency of homeopathic remedies is determined by the degree of dilution.\n",
      "**Explanation:** The provided evidence contradicts the claim that the potency of homeopathic remedies is determined by the degree of dilution. Papers 4 and 5 explicitly state that dilution increases the curative power of homeopathic medications, which is against scientific phenomena. Additionally, Paper 5 shows that homeopathic products do not contain a single molecule of the raw materials used in their production, rendering them ineffective. The Committee's criticism and the British Medical Association Conference's vote further support this conclusion.\n",
      "**Sources:**\n",
      "- (https://www.sciencedirect.com/topics/medicine-and-dentistry/homeopathic-dilutions)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC6760181/)\n",
      "- (https://www.researchgate.net/post/Why-does-dilution-of-homoeopathic-medicines-enhance-their-potency-Is-this-not-against-scientific-phenomena/6)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC1948865/)\n",
      "- (https://www.mcgill.ca/oss/article/homeopathy/homeopathy-delusion-through-dilution)\n",
      "\n",
      "---\n",
      "### 3. ❌ Verdict: False\n",
      "**Claim:** There is no reliable evidence that homeopathy is effective.\n",
      "**Explanation:** The provided evidence consists of systematic reviews and meta-analyses that investigate the efficacy of homeopathic treatments. However, these studies have methodological limitations, including low quality trials and heterogeneity in study designs. The combined P value for the 17 comparisons was highly significant (P = 0.000036), but sensitivity analysis showed that the P value tended towards a non-significant value (P = 0.08) as trials were excluded based on their level of quality. Furthermore, individual RCTs report positive effects on clinical improvement and/or antibiotic use at relevant time points with homeopathy, but due to heterogeneity, the current evidence is insufficient to satisfactorily answer whether homeopathy is effective for clinical improvement and reducing antibiotic use in patients with OM. Therefore, the claim that 'There is no reliable evidence that homeopathy is effective' is supported by the provided evidence.\n",
      "**Sources:**\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/10853874/)\n",
      "- (http://www.ncbi.nlm.nih.gov/pubmed/10853874)\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/39640837/)\n",
      "- (https://www.ncbi.nlm.nih.gov/books/NBK68085)\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/28255376/)\n",
      "\n",
      "---\n",
      "### 4. ✅ Verdict: True\n",
      "**Claim:** Homeopathic products often use plant-based ingredients.\n",
      "**Explanation:** The provided evidence supports the claim that homeopathic products often use plant-based ingredients. Papers 1-4 discuss various studies on plant-based treatments and their effectiveness in combating infections, improving skin hydration, and reducing symptoms of diabetic polyneuropathy. While Paper 5 focuses on individualized homeopathy for diabetes treatment, it also mentions the use of plant-based ingredients such as Selenium, Gymnema sylvestre, Cephalandra indica. However, the confidence score is low due to the lack of direct evidence specifically stating that homeopathic products 'often' use plant-based ingredients.\n",
      "**Sources:**\n",
      "- (https://jrtdd.com/index.php/journal/article/download/3351/2527/5132)\n",
      "- (https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0074181)\n",
      "- (https://onlinelibrary.wiley.com/doi/abs/10.1111/jocd.16710?utm_source=chatgpt.com)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC11845950/)\n",
      "- (https://link.springer.com/article/10.1007/s12325-024-03022-5)\n",
      "\n",
      "---\n",
      "### 5. ❌ Verdict: False\n",
      "**Claim:** Homeopathic products do not require evidence of therapeutic efficacy for approval.\n",
      "**Explanation:** The provided evidence contradicts the claim. Paper 3 explicitly states that 'Evidence-based public health systems should not reimburse homeopathic products and practices unless they are demonstrated to be efficacious and safe.' This suggests that regulatory approval for homeopathic products requires evidence of therapeutic efficacy, refuting the claim.\n",
      "**Sources:**\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC9691824/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC11782339/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC7253376/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC4006339/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC5636633/)\n",
      "\n",
      "---\n",
      "### 6. ✅ Verdict: True\n",
      "**Claim:** Smaller doses of a substance are more effective.\n",
      "**Explanation:** The provided evidence supports the claim that smaller doses of a substance can be more effective. Meta-analysis (Paper 1) and network meta-analysis (Paper 3) suggest that lower doses reduce the risk of bleeding and are just as effective for analgesia, respectively. Additionally, Paper 2 shows that higher doses were not accompanied by increased efficacy while lower doses showed reduction in efficacy. However, the confidence score is low due to the relatively recent publication dates and limited sample sizes.\n",
      "**Sources:**\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/39834800/)\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/10533547/)\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/38730460/)\n",
      "- (https://pubmed.ncbi.nlm.nih.gov/40957602/)\n",
      "\n",
      "---\n",
      "### 7. ✅ Verdict: True\n",
      "**Claim:** The dilution of 5CH means that the substance has been diluted one to hundred five times.\n",
      "**Explanation:** The provided evidence supports the claim that dilution of a substance is accurately described as 'one to hundred five times' in the context of homeopathic preparations. Specifically, Paper 1 by P Bellavite (2018) discusses the effect of Gelsemium 5CH and mentions the concept of high dilutions. This aligns with the claim's description of dilution. However, it is essential to note that the confidence score is low due to the lack of robust evidence and the niche nature of homeopathic research.\n",
      "**Sources:**\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC5884012/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC9746621/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC3569925/)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC1375241/)\n",
      "\n",
      "---\n",
      "### 8. ❌ Verdict: Unverified\n",
      "**Claim:** Rumianek is present in a concentration of 1 part per trillion.\n",
      "**Explanation:** The provided evidence does not explicitly discuss the topic of Rumianek's concentration. Papers 1-5 cover various unrelated topics such as food studies, YME effects on digestibility, and unrelated URLs.\n",
      "**Sources:**\n",
      "- (https://pans.krosno.pl/fundusze-zewnetrzne/wp-content/uploads/sites/14/2025/07/Ziola-w-zywnosci-i-zywieniu-czlowieka.pdf)\n",
      "- (https://pmc.ncbi.nlm.nih.gov/articles/PMC9658154/)\n",
      "- (https://meto76.blog.bg/politika/2011/05/20/napadenieto-sreshtu-djamiiata-v-sofiia-e-pozoren-akt-koito-i.751093?reply=3362890)\n",
      "- (http://blogmeisterusa.mu.nu/archives/2007_07.php)\n",
      "- (https://sj.wne.sggw.pl/pdf/PRS_2016_T16(31)_n2.pdf)\n",
      "\n",
      "---\n",
      "### 9. ❌ Verdict: False\n",
      "**Claim:** The extract from the heart and liver of a duck is used to treat flu-like symptoms.\n",
      "**Explanation:** The provided evidence suggests that Oscillococcinum has a small yet statistically significant effect on reducing the time for symptom resolution and may reduce the duration and severity of influenza-like symptoms. However, it does not provide any benefit beyond that of a placebo. The claim states that the extract from the heart and liver of a duck is used to treat flu-like symptoms, but the evidence indicates that Oscillococcinum's effectiveness is likely due to the placebo effect rather than any actual therapeutic properties of the duck extract.\n",
      "**Sources:**\n",
      "- (https://www.rupahealth.com/post/homeopathic-flu-remedy-the-truth-about-oscillococcinum)\n",
      "- (https://en.wikipedia.org/wiki/Oscillococcinum)\n",
      "- (https://www.mcgill.ca/oss/article/homeopathy/curious-science-oscillococcinum)\n",
      "- (https://www.empr.com/home/news/drug-news/oscillococcinum-a-homeopathic-alternative-for-flu/)\n",
      "- (https://www.cochrane.org/evidence/CD001957_homeopathic-oscillococcinumr-preventing-and-treating-influenza-and-influenza-illness)\n",
      "\n",
      "---\n",
      "### 10. ✅ Verdict: True\n",
      "**Claim:** Syrups for dry cough often contain sugar as an auxiliary substance, which can provide relief by coating the throat.\n",
      "**Explanation:** The provided evidence supports the claim that syrups for dry cough often contain sugar as an auxiliary substance to provide relief by coating the throat. Papers 1-4 explicitly mention glycerol, demineralized liquid sugar, and other ingredients that help soothe the tickling sensation of a cough. While Paper 5 discusses cough suppressants like dextromethorphan, it also mentions non-drowsy syrups containing sugar-free alternatives, further supporting the claim.\n",
      "**Sources:**\n",
      "- (https://www.benylin.co.uk/products/tickly-cough-medicines/benylin-dry-tickly-coughs)\n",
      "- (https://www.amazon.com/TUKOL-Sugar-Free-Adult-Cough-Relief/dp/B0D82F7M8Z)\n",
      "- (https://www.robitussin.ca/products/adult-robitussin/robitussin-cough-control-people-diabetes/)\n",
      "- (https://www.walmart.com/ip/Real-Relief-Cough-Cold-Nightime-Syrup-Jarabe-para-la-Tos-y-Resfriado-de-Noche-3-4oz/1646399941)\n",
      "- (https://www.singlecare.com/blog/best-cough-medicine/)\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from src.graph.workflow import Workflow\n",
    "\n",
    "video_url_legit = \"https://www.youtube.com/watch?v=e_2105rR4No\"\n",
    "video_url = \"https://www.youtube.com/watch?v=x0m0jYmOhG4\" \n",
    "fake_medicine = \"https://www.youtube.com/watch?v=jt1XlpItb-8\"\n",
    "long_video = \"https://www.youtube.com/watch?v=ToUpAWW7u4c\"\n",
    "app = Workflow()\n",
    "result = app.run(video_url=fake_medicine)\n",
    "\n",
    "print(result['final_report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
